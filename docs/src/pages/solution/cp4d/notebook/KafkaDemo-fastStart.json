{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9e2bda70-e309-402d-a558-d279f9462432"
   },
   "source": [
    "## Install confluent kafka library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fd2b82a9-f806-4b1a-a6ae-4303dbabdaf1"
   },
   "outputs": [],
   "source": [
    "!pip install confluent-kafka"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "799994fc-d538-437c-9d57-3e3d3db3bb8e"
   },
   "source": [
    "## Set environment for Kafka application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0b624f33-b443-480e-a462-06bcf0a72614"
   },
   "outputs": [],
   "source": [
    "%env KAFKA_BROKERS=eda-dev-kafka-bootstrap-eventstreams.gse-eda-2021-1-0143c5dd31acd8e030a1d6e0ab1380e3-0000.us-east.containers.appdomain.cloud:443\n",
    "%env KAFKA_USER=qijun-test\n",
    "%env KAFKA_PASSWORD=<kafka password>\n",
    "%env KAFKA_CERT=<certificate path>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8d3ec954-ae3a-421a-af56-248f7afc83ec"
   },
   "source": [
    "## Kafka Producer class definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "db894876-7422-4d4b-b18f-657f5e92c686"
   },
   "outputs": [],
   "source": [
    "import json, os\n",
    "from confluent_kafka import KafkaError, Producer\n",
    "\n",
    "class KafkaProducer:\n",
    "\n",
    "    def __init__(self, groupID = \"KafkaProducer\"):\n",
    "        # Get the producer configuration\n",
    "        self.producer_conf = self.getProducerConfiguration(groupID)\n",
    "        # Create the producer\n",
    "        self.producer = Producer(self.producer_conf)\n",
    "\n",
    "    def getProducerConfiguration(self,groupID):\n",
    "        try:\n",
    "            options ={\n",
    "                    'bootstrap.servers': os.environ['KAFKA_BROKERS'],\n",
    "                    'group.id': groupID\n",
    "            }\n",
    "            if (os.getenv('KAFKA_PASSWORD','') != ''):\n",
    "                # Set security protocol common to ES on prem and on IBM Cloud\n",
    "                options['security.protocol'] = 'SASL_SSL'\n",
    "                # Depending on the Kafka User, we will know whether we are talking to ES on prem or on IBM Cloud\n",
    "                # If we are connecting to ES on IBM Cloud, the SASL mechanism is plain\n",
    "                if (os.getenv('KAFKA_USER','') == 'token'):\n",
    "                    options['sasl.mechanisms'] = 'PLAIN'\n",
    "                # If we are connecting to ES on OCP, the SASL mechanism is scram-sha-512\n",
    "                else:\n",
    "                    options['sasl.mechanisms'] = 'SCRAM-SHA-512'\n",
    "                # Set the SASL username and password\n",
    "                options['sasl.username'] = os.getenv('KAFKA_USER','')\n",
    "                options['sasl.password'] = os.getenv('KAFKA_PASSWORD','')\n",
    "            # If we are talking to ES on prem, it uses an SSL self-signed certificate.\n",
    "            # Therefore, we need the CA public certificate for the SSL connection to happen.\n",
    "            if (os.path.isfile(os.getenv('KAFKA_CERT','/certs/es-cert.pem'))):\n",
    "                options['ssl.ca.location'] = os.getenv('KAFKA_CERT','/certs/es-cert.pem')\n",
    "            \n",
    "            # Print out the producer configuration\n",
    "            self.printProducerConfiguration(options)\n",
    "\n",
    "            return options\n",
    "\n",
    "        except KeyError as error:\n",
    "            print('[KafkaProducer] - [ERROR] - A required environment variable does not exist: ' + error)\n",
    "            exit(1)\n",
    "\n",
    "    def printProducerConfiguration(self,options):\n",
    "        # Printing out producer config for debugging purposes        \n",
    "        print(\"[KafkaProducer] - This is the configuration for the producer:\")\n",
    "        print(\"[KafkaProducer] - -------------------------------------------\")\n",
    "        print('[KafkaProducer] - Bootstrap Server:      {}'.format(options['bootstrap.servers']))\n",
    "        if (os.getenv('KAFKA_PASSWORD','') != ''):\n",
    "            # Obfuscate password\n",
    "            if (len(options['sasl.password']) > 3):\n",
    "                obfuscated_password = options['sasl.password'][0] + \"*****\" + options['sasl.password'][len(options['sasl.password'])-1]\n",
    "            else:\n",
    "                obfuscated_password = \"*******\"\n",
    "            print('[KafkaProducer] - Security Protocol:     {}'.format(options['security.protocol']))\n",
    "            print('[KafkaProducer] - SASL Mechanism:        {}'.format(options['sasl.mechanisms']))\n",
    "            print('[KafkaProducer] - SASL Username:         {}'.format(options['sasl.username']))\n",
    "            print('[KafkaProducer] - SASL Password:         {}'.format(obfuscated_password))\n",
    "            if (os.path.isfile(os.getenv('KAFKA_CERT','/certs/es-cert.pem'))): \n",
    "                print('[KafkaProducer] - SSL CA Location:       {}'.format(options['ssl.ca.location']))\n",
    "        print(\"[KafkaProducer] - -------------------------------------------\")\n",
    "\n",
    "    def delivery_report(self,err, msg):\n",
    "        \"\"\" Called once for each message produced to indicate delivery result. Triggered by poll() or flush(). \"\"\"\n",
    "        if err is not None:\n",
    "            print('[KafkaProducer] - [ERROR] - Message delivery failed: {}'.format(err))\n",
    "        else:\n",
    "            print('[KafkaProducer] - Message delivered to {} [{}]'.format(msg.topic(), msg.partition()))\n",
    "\n",
    "    def publishEvent(self, topicName, eventToSend, keyName):\n",
    "        # Print the event to send\n",
    "        dataStr = json.dumps(eventToSend)\n",
    "        # Produce the message\n",
    "        self.producer.produce(topicName,key=eventToSend[keyName],value=dataStr.encode('utf-8'), callback=self.delivery_report)\n",
    "        # Flush\n",
    "        self.producer.flush()\n",
    "\n",
    "    #def publishEvent(self, topicName, eventToSend):\n",
    "    #    # Print the event to send\n",
    "    #    #dataStr = json.dumps(eventToSend)\n",
    "    #    # Produce the message\n",
    "    #    self.producer.produce(topicName,value=eventToSend.encode('utf-8'), callback=self.delivery_report)\n",
    "    #    # Flush\n",
    "    #    self.producer.flush()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "002c22d8-36ab-4515-b9c4-acc544ce0884"
   },
   "source": [
    "## Kafka Producer send message to Kafka server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7c4f6c4e-f192-4a29-a464-37c0bcfc84f3"
   },
   "outputs": [],
   "source": [
    "#import argparse\n",
    "#from KafkaProducer import KafkaProducer\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # Parse arguments\n",
    "    #parser = argparse.ArgumentParser(description=\"Message Producer Example\")\n",
    "    #parser.add_argument('-t', dest=\"topic\", required=True, help=\"Topic name\")\n",
    "    #args = parser.parse_args()\n",
    "    \n",
    "    # Create the event to be sent\n",
    "    event = {\"eventKey\" : \"WF-TEST\", \"message\" : \"This is WF-TEST message\"}\n",
    "    \n",
    "    # Print it out\n",
    "    print(\"--- Event to be published: ---\")\n",
    "    print(event)\n",
    "    print(\"----------------------------------------\")\n",
    "    \n",
    "    # Create the Kafka Producer\n",
    "    kafka_producer = KafkaProducer()\n",
    "    # Publish the event\n",
    "    kafka_producer.publishEvent(\"test\",event,\"eventKey\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "452a1f4b-a04a-4872-9d06-45413fa7d207"
   },
   "source": [
    "## Kafka consumer class definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "08d46d3e-9186-4043-9bf4-2deb5f1e5056"
   },
   "outputs": [],
   "source": [
    "import json,os,csv\n",
    "from confluent_kafka import Consumer, KafkaError\n",
    "\n",
    "\n",
    "class KafkaConsumer:\n",
    "\n",
    "    def __init__(self, topic_name = \"kafka-producer\", groupID = 'KafkaConsumer-F20', autocommit = True):\n",
    "        # Get the consumer configuration\n",
    "        self.consumer_conf = self.getConsumerConfiguration(groupID, autocommit)\n",
    "        # Create the Avro consumer\n",
    "        self.consumer = Consumer(self.consumer_conf)\n",
    "        # Subscribe to the topic\n",
    "        self.consumer.subscribe([topic_name])\n",
    "\n",
    "    def getConsumerConfiguration(self, groupID, autocommit):\n",
    "        try:\n",
    "            options ={\n",
    "                    'bootstrap.servers': os.environ['KAFKA_BROKERS'],\n",
    "                    'group.id': groupID,\n",
    "                    'auto.offset.reset': \"earliest\",\n",
    "                    'enable.auto.commit': autocommit,\n",
    "            }\n",
    "            if (os.getenv('KAFKA_PASSWORD','') != ''):\n",
    "                # Set security protocol common to ES on prem and on IBM Cloud\n",
    "                options['security.protocol'] = 'SASL_SSL'\n",
    "                # Depending on the Kafka User, we will know whether we are talking to ES on prem or on IBM Cloud\n",
    "                # If we are connecting to ES on IBM Cloud, the SASL mechanism is plain\n",
    "                if (os.getenv('KAFKA_USER','') == 'token'):\n",
    "                    options['sasl.mechanisms'] = 'PLAIN'\n",
    "                # If we are connecting to ES on OCP, the SASL mechanism is scram-sha-512\n",
    "                else:\n",
    "                    options['sasl.mechanisms'] = 'SCRAM-SHA-512'\n",
    "                # Set the SASL username and password\n",
    "                options['sasl.username'] = os.getenv('KAFKA_USER','')\n",
    "                options['sasl.password'] = os.getenv('KAFKA_PASSWORD','')\n",
    "            # If we are talking to ES on prem, it uses an SSL self-signed certificate.\n",
    "            # Therefore, we need the CA public certificate for the SSL connection to happen.\n",
    "            if (os.path.isfile(os.getenv('KAFKA_CERT','/certs/es-cert.pem'))):\n",
    "                options['ssl.ca.location'] = os.getenv('KAFKA_CERT','/certs/es-cert.pem')\n",
    "\n",
    "            # Print out the producer configuration\n",
    "            self.printConsumerConfiguration(options)\n",
    "\n",
    "            return options\n",
    "\n",
    "        except KeyError as error:\n",
    "            print('[KafkaConsumer] - [ERROR] - A required environment variable does not exist: ' + error)\n",
    "            exit(1)\n",
    "    \n",
    "    def printConsumerConfiguration(self,options):\n",
    "        # Printing out consumer config for debugging purposes        \n",
    "        print(\"[KafkaConsumer] - This is the configuration for the consumer:\")\n",
    "        print(\"[KafkaConsumer] - -------------------------------------------\")\n",
    "        print('[KafkaConsumer] - Bootstrap Server:      {}'.format(options['bootstrap.servers']))\n",
    "        if (os.getenv('KAFKA_PASSWORD','') != ''):\n",
    "            # Obfuscate password\n",
    "            if (len(options['sasl.password']) > 3):\n",
    "                obfuscated_password = options['sasl.password'][0] + \"*****\" + options['sasl.password'][len(options['sasl.password'])-1]\n",
    "            else:\n",
    "                obfuscated_password = \"*******\"\n",
    "            print('[KafkaConsumer] - Security Protocol:     {}'.format(options['security.protocol']))\n",
    "            print('[KafkaConsumer] - SASL Mechanism:        {}'.format(options['sasl.mechanisms']))\n",
    "            print('[KafkaConsumer] - SASL Username:         {}'.format(options['sasl.username']))\n",
    "            print('[KafkaConsumer] - SASL Password:         {}'.format(obfuscated_password))\n",
    "            if (os.path.isfile(os.getenv('KAFKA_CERT','/certs/es-cert.pem'))): \n",
    "                print('[KafkaConsumer] - SSL CA Location:       {}'.format(options['ssl.ca.location']))\n",
    "        print('[KafkaConsumer] - Offset Reset:          {}'.format(options['auto.offset.reset']))\n",
    "        print('[KafkaConsumer] - Autocommit:            {}'.format(options['enable.auto.commit']))\n",
    "        print(\"[KafkaConsumer] - -------------------------------------------\")\n",
    "    \n",
    "    # Prints out and returns the decoded events received by the consumer\n",
    "    def traceResponse(self, msg):\n",
    "        print('[KafkaConsumer] - Next Message consumed from {} partition: [{}] at offset: {}\\n\\tkey: {}\\n\\tvalue: {}'\n",
    "                    .format(msg.topic(), msg.partition(), msg.offset(), msg.key().decode('utf-8'), msg.value().decode('utf-8')))\n",
    "\n",
    "    # Polls for next event\n",
    "    def pollNextEvent(self):\n",
    "      # Poll for messages\n",
    "      msg = self.consumer.poll(timeout=10.0)\n",
    "\n",
    "            \n",
    "      if msg is None:\n",
    "        print(\"[KafkaConsumer] - [INFO] - No new messages on the topic\")\n",
    "        \n",
    "      f = open('/project_data/data_asset/data2.csv', 'w')\n",
    "      w = csv.writer(f, delimiter = ',') \n",
    "      fields = ['container_id', 'timestamp', 'product_id', 'temperature','target_temperature','ambiant_temperature','kilowatts','content_type','oxygen_level','nitrogen_level', \\\n",
    "                     'carbon_dioxide_level', 'humidity_level', 'fan_1', 'vent_2', 'vent_3', 'time_door_open', 'latitude', 'longitude', 'defrost_cycle', 'maintenance_required'] \n",
    "      w.writerow(fields)\n",
    "        \n",
    "      while not (msg is None):\n",
    "\n",
    "        if msg.error():\n",
    "            if (\"PARTITION_EOF\" in msg.error()):\n",
    "                print(\"[KafkaConsumer] - [INFO] - End of partition\")\n",
    "            else:\n",
    "                print(\"[KafkaConsumer] - [ERROR] - Consumer error: {}\".format(msg.error()))\n",
    "        else:\n",
    "\n",
    "            # Print the message\n",
    "            # self.traceResponse(msg)\n",
    "            loaded_json = json.loads(msg.value().decode('utf-8'))\n",
    "            payload = loaded_json[\"payload\"].strip('()')\n",
    "            msg_list = list(payload.split(\",\")) \n",
    "            #msg_json = json.dumps(msg.value().decode('utf-8'))\n",
    "            #print(msg_list)\n",
    "            w.writerow(msg_list)\n",
    "            \n",
    "        msg = self.consumer.poll(timeout=10.0)    \n",
    "      \n",
    "      f.close()\n",
    "      \n",
    "      \n",
    "    \n",
    "    def close(self):\n",
    "        self.consumer.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "96429fe1-bd52-4d59-b0a1-34683df199a9"
   },
   "source": [
    "## Kafka consumer read message from Kafka server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5670d0c7-3f6c-4c75-9265-f133b5ea1230"
   },
   "outputs": [],
   "source": [
    "#import argparse\n",
    "#from KafkaConsumer import KafkaConsumer\n",
    "\n",
    "####################### MAIN #######################\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    # Parse arguments\n",
    "    #parser = argparse.ArgumentParser(description=\"Message Consumer Example\")\n",
    "    #parser.add_argument('-t', dest=\"topic\", required=True, help=\"Topic name\")\n",
    "    #args = parser.parse_args()\n",
    "\n",
    "    # Create a Kafka Consumer\n",
    "    kafka_consumer = KafkaConsumer(\"telemetries\")\n",
    "    # Poll for next message\n",
    "    \n",
    "    message = kafka_consumer.pollNextEvent()\n",
    "\n",
    "    # Close the consumer\n",
    "    kafka_consumer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a9186eea-4edf-4fc5-8a38-a67bf9f2cb31"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
